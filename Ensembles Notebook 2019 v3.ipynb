{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Ensembles (11/05/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "# To load datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# To import decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# To import random forest\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# To import adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "\n",
    "# To import bagging\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "\n",
    "# To display a tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# To measure accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "\n",
    "# To support plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "class DummyScaler:\n",
    "    \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "def create_scaler_dummy():\n",
    "    return DummyScaler()\n",
    "    \n",
    "def create_scaler_standard():\n",
    "    return StandardScaler()\n",
    "\n",
    "def create_scaler_minmax():\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def crete_scaler_binarizer():\n",
    "    return Binarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Classification</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>The dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use Pen-Based Recognition of Handwritten Digits Data Set.\n",
    "\n",
    "This is a quite old dataset (1998), it contains features derived from pen trajectories arising from handwritten digits (0â€“9) from 44 subjects.\n",
    "\n",
    "You can find more information about it here:\n",
    "https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file(url):\n",
    "    filename = os.path.basename(url)\n",
    "    if not os.path.exists(filename):\n",
    "        response = requests.get(url)\n",
    "        open(filename, 'wb').write(response.content)\n",
    "    return filename\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "X_train, y_train = load_svmlight_file(download_file('https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/pendigits'), dtype=np.int32)\n",
    "y_train = y_train.astype(np.int32)\n",
    "X_train = X_train.toarray()\n",
    "X_test, y_test = load_svmlight_file(download_file('https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/pendigits.t'), dtype=np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Decision Tree Classifier</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = GridSearchCV(DecisionTreeClassifier(random_state=520),\n",
    "                          cv=5,\n",
    "                          param_grid={\n",
    "                              \"max_depth\": list(range(1, 40, 2)),\n",
    "                              \"min_samples_split\": list(range(2, 5, 2))\n",
    "                          })\n",
    "model_tree.fit(X_train, y_train)\n",
    "print('The parameters found by CV search:')\n",
    "print(model_tree.best_params_)\n",
    "y_test_hat = model_tree.predict(X_test)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Random Forest Classifier</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(n_estimators=100, random_state=520, \n",
    "                                      max_depth=model_tree.best_params_['max_depth'],\n",
    "                                      min_samples_split=model_tree.best_params_['min_samples_split'],\n",
    "                                      n_jobs=-1)\n",
    "model_forest.fit(X_train, y_train)\n",
    "y_test_hat = model_forest.predict(X_test)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Ada Boost Classifier</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adaboost = AdaBoostClassifier(DecisionTreeClassifier(random_state=520,\n",
    "                                                           max_depth=model_tree.best_params_['max_depth'],\n",
    "                                                           min_samples_split=model_tree.best_params_['min_samples_split']))\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "y_test_hat = model_adaboost.predict(X_test)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Bagging Classifier</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagging = BaggingClassifier(DecisionTreeClassifier(random_state=520,\n",
    "                                                         max_depth=model_tree.best_params_['max_depth'],\n",
    "                                                         min_samples_split=model_tree.best_params_['min_samples_split']),\n",
    "                                  bootstrap=False,\n",
    "                                  max_samples=0.6,\n",
    "                                  bootstrap_features=False,\n",
    "                                  max_features=0.6,\n",
    "                                  n_estimators=100)\n",
    "model_bagging.fit(X_train, y_train)\n",
    "y_test_hat = model_bagging.predict(X_test)\n",
    "\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Regression</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider that dataset:\n",
    "http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contain estimates of the percentage of body fat determined by underwater weighing and various body circumference measurements for 252 men.\n",
    "\n",
    "Accurate measurement of body fat is inconvenient/costly and it is desirable to have easy methods of estimating body fat that are not inconvenient/costly.\n",
    "\n",
    "Thanks to StatLib and Roger W. Johnson who contributed this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the data set are:\n",
    "\n",
    "* Density determined from underwater weighing\n",
    "* Percent body fat from Siri's (1956) equation\n",
    "* Age (years)\n",
    "* Weight (lbs)\n",
    "* Height (inches)\n",
    "* Neck circumference (cm)\n",
    "* Chest circumference (cm)\n",
    "* Abdomen 2 circumference (cm)\n",
    "* Hip circumference (cm)\n",
    "* Thigh circumference (cm)\n",
    "* Knee circumference (cm)\n",
    "* Ankle circumference (cm)\n",
    "* Biceps (extended) circumference (cm)\n",
    "* Forearm circumference (cm)\n",
    "* Wrist circumference (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a realistic model: the input containts all the measurements, the output is bodyfat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "X_complex = vals[:, 2:]\n",
    "y_complex = vals[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    return math.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Greater is better to make sure the signs are not flipped\n",
    "rmse_score = metrics.make_scorer(rmse_loss, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = GridSearchCV(DecisionTreeRegressor(random_state=520, max_features='sqrt'),\n",
    "                          cv=5,\n",
    "                          iid=False,\n",
    "                          param_grid={\n",
    "                             \"max_depth\": list(range(1, 40, 2)),\n",
    "                             \"min_samples_split\": list(range(2, 5, 2)),\n",
    "                          })\n",
    "model_tree.fit(X_complex, y_complex)\n",
    "print('The parameters found by CV search:')\n",
    "print(model_tree.best_params_)\n",
    "test_score = cross_validate(model_tree, X_complex, y_complex, cv=10, scoring=rmse_score)['test_score']\n",
    "\n",
    "print('RMSE:', np.mean(test_score))\n",
    "\n",
    "y_complex_hat = model_tree.predict(X_complex)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(y_complex, y_complex_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Random Forest Regressor</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestRegressor(n_estimators=100, random_state=520, \n",
    "                                     max_depth=model_tree.best_params_['max_depth'],\n",
    "                                     min_samples_split=model_tree.best_params_['min_samples_split'],\n",
    "                                     max_features='sqrt',\n",
    "                                     n_jobs=-1)\n",
    "model_forest.fit(X_complex, y_complex)\n",
    "test_score = cross_validate(model_forest, X_complex, y_complex, cv=10, scoring=rmse_score)['test_score']\n",
    "\n",
    "print('RMSE:', np.mean(test_score))\n",
    "\n",
    "y_complex_hat = model_forest.predict(X_complex)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(y_complex, y_complex_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = GridSearchCV(RandomForestRegressor(random_state=598, max_features='sqrt'),\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                            iid=False,\n",
    "                            param_grid={\n",
    "                                'n_estimators': [300, 400, 500],\n",
    "                                'max_depth': [7, 8, 9],\n",
    "                                'min_samples_split': [4, 6, 8]\n",
    "                            })\n",
    "model_forest.fit(X_complex, y_complex)\n",
    "print('The parameters found by CV search:')\n",
    "print(model_forest.best_params_)\n",
    "test_score = cross_validate(model_forest.best_estimator_, X_complex, y_complex, cv=10, scoring=rmse_score)['test_score']\n",
    "\n",
    "print('RMSE:', np.mean(test_score))\n",
    "\n",
    "y_complex_hat = model_forest.predict(X_complex)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(y_complex, y_complex_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>AdaBoost Regressor</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model_adaboost = AdaBoostRegressor(DecisionTreeRegressor(random_state=520,\n",
    "                                                         max_depth=model_tree.best_params_['max_depth'],\n",
    "                                                         min_samples_split=model_tree.best_params_['min_samples_split'],\n",
    "                                                         max_features='sqrt'))\n",
    "model_adaboost.fit(X_complex, y_complex)\n",
    "test_score = cross_validate(model_adaboost, X_complex, y_complex, cv=10, scoring=rmse_score)['test_score']\n",
    "\n",
    "print('RMSE:', np.mean(test_score))\n",
    "\n",
    "y_complex_hat = model_adaboost.predict(X_complex)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(y_complex, y_complex_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Bagging Regressor</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bagging = BaggingRegressor(DecisionTreeRegressor(random_state=520,\n",
    "                                                         max_depth=model_tree.best_params_['max_depth'],\n",
    "                                                         min_samples_split=model_tree.best_params_['min_samples_split'],\n",
    "                                                         max_features='sqrt',),\n",
    "                                  bootstrap=False,\n",
    "                                  max_samples=0.6,\n",
    "                                  bootstrap_features=False,\n",
    "                                  max_features=0.6,\n",
    "                                  n_estimators=100)\n",
    "model_bagging.fit(X_complex, y_complex)\n",
    "test_score = cross_validate(model_bagging, X_complex, y_complex, cv=10, scoring=rmse_score)['test_score']\n",
    "\n",
    "print('RMSE:', np.mean(test_score))\n",
    "\n",
    "y_complex_hat = model_bagging.predict(X_complex)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.scatter(y_complex, y_complex_hat)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
