{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Cluster Analysis (11/21/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>\n",
    "### <center>Special thanks to Maziar Kasaei for suggestions</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: TO SUPPORT INTERACTIVE PLOTS IN JUPYTER LAB, RUN**\n",
    "\n",
    "conda install -c conda-forge nodejs\n",
    "\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "# To load datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# To import clustering-related methods\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# To measure accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# To support plots\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>K-Means</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Digits dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains images of hand-written digits: 10 classes where each class refers to a digit.\n",
    "\n",
    "Preprocessing programs made available by NIST were used to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use PCA (principal component analysis) to reduce dimension to 2, so we can simply visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)\n",
    "X_reduced = pca_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use closure to store the related variables\n",
    "def create_plot_kmeans_digits(_X, _y, _n_classes):\n",
    "    X, y = _X, _y\n",
    "    n_classes = _n_classes\n",
    "    colors = np.array([cm.tab20(i) for i in range(100)])\n",
    "    def plot_kmeans_digits(n_clusters=10):\n",
    "        expand=1\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10, random_state=520, max_iter=1000)\n",
    "        kmeans.fit(X)\n",
    "        y_predicted = kmeans.predict(X)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.plot((np.min(X_reduced[:, 0])-expand, np.max(X_reduced[:, 0])+expand), \n",
    "                 (np.min(X_reduced[:, 1])-expand, np.max(X_reduced[:, 1])+expand),\n",
    "                 alpha=0.0)\n",
    "        xlim = ax1.get_xlim()\n",
    "        ylim = ax1.get_ylim()\n",
    "        ax1.scatter(X_reduced[:, 0], X_reduced[:, 1], c=colors[y_predicted])\n",
    "        ax1.set_xlabel('pca #1')\n",
    "        ax1.set_ylabel('pca #2') \n",
    "        centers = np.array(kmeans.cluster_centers_)\n",
    "        ax1.scatter(centers[:, 0], centers[:, 1], marker=\"x\", color='k', s=64)\n",
    "        matrix = np.zeros((n_clusters, n_classes))\n",
    "        for cluster in range(n_clusters):\n",
    "            for cl in range(n_classes):\n",
    "                matrix[cluster, cl] = np.sum(y[y_predicted == cluster]==cl)\n",
    "        sns.heatmap(matrix, annot=True, fmt='g', ax=ax2)\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Cluster')\n",
    "        print('Inertia:', kmeans.inertia_)\n",
    "        print('Homogenity:', metrics.homogeneity_score(y, y_predicted))\n",
    "        print('Completeness:', metrics.completeness_score(y, y_predicted))\n",
    "        plt.show()\n",
    "    return plot_kmeans_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_widget = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    continuous_update=False,\n",
    "    description='N clusters:')\n",
    "interact(create_plot_kmeans_digits(X_reduced, y, 10),\n",
    "         n_clusters=n_clusters_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways of cluster evaluation. \n",
    "- Class labels are not available: within-cluster sum of squares (inertia) can be used.\n",
    "- Class labels are available: measures like Completeness and Homogeneity can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = range(1, 30)\n",
    "inertia = np.zeros(len(n_clusters))\n",
    "homogeneity = np.zeros(len(n_clusters))\n",
    "completeness = np.zeros(len(n_clusters))\n",
    "for i, clusters in enumerate(n_clusters):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=clusters, n_init=10, random_state=520, max_iter=1000)\n",
    "    kmeans.fit(X)\n",
    "    inertia[i] = kmeans.inertia_\n",
    "    y_predicted = kmeans.predict(X)\n",
    "    homogeneity[i] = metrics.homogeneity_score(y, y_predicted)\n",
    "    completeness[i] = metrics.completeness_score(y, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_clusters, completeness)\n",
    "plt.title('Kmeans: completeness')\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Completeness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_clusters, homogeneity)\n",
    "plt.title('Kmeans: homogeneity')\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Homogeneity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_clusters, inertia)\n",
    "plt.title('Kmeans: inertia')\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Hierarchical clustering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Parkinsons Data Set</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parkinsons disease: https://www.mayoclinic.org/diseases-conditions/parkinsons-disease/symptoms-causes/syc-20376055"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://archive.ics.uci.edu/ml/datasets/parkinsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* name - ASCII subject name and recording number\n",
    "* MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "* MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "* MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "* MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\n",
    "* MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "* NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "* status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "* RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "* DFA - Signal fractal scaling exponent\n",
    "* spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data')\n",
    "print(df.columns)\n",
    "X = df.drop(['name','status'], axis=1).values\n",
    "y = df['status'].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use a closure to store the related variables\n",
    "def create_plot_hierarchical(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    n_classes = len(np.unique(y))\n",
    "    def plot_hierarchical(threshold=1.0, method='single'):\n",
    "        expand = 1\n",
    "        linkage = hierarchy.linkage(X, method=method, metric='euclidean')\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "        \n",
    "        hierarchy.dendrogram(linkage,\n",
    "                   labels=y,\n",
    "                   leaf_rotation=0,\n",
    "                   leaf_font_size=7,\n",
    "                   color_threshold=threshold, \n",
    "                   ax=ax1)\n",
    "        \n",
    "        y_predicted = hierarchy.fcluster(linkage, t=threshold, criterion='distance')\n",
    "        \n",
    "        n_clusters = len(np.unique(y_predicted))\n",
    "        \n",
    "        matrix = np.zeros((n_clusters, n_classes))\n",
    "        for cluster in range(n_clusters):\n",
    "            for cl in range(n_classes):\n",
    "                matrix[cluster, cl] = np.sum(y[y_predicted == cluster+1]==cl)\n",
    "        sns.heatmap(matrix, annot=True, fmt='g', ax=ax2)\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Cluster')\n",
    "        print('Homogenity:', metrics.homogeneity_score(y, y_predicted))\n",
    "        print('Completeness:', metrics.completeness_score(y, y_predicted))\n",
    "        plt.show()\n",
    "    return plot_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_widget = widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=0.0,\n",
    "    max=10.0,\n",
    "    step=0.05,\n",
    "    continuous_update=False,\n",
    "    description='Threshold:')\n",
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "interact(create_plot_hierarchical(X_scaled, y),\n",
    "         threshold=threshold_widget, method=methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>SPECT Heart Data Set</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datset: https://archive.ics.uci.edu/ml/datasets/spect+heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spect/SPECTF.train', header=None)\n",
    "X = df.values[:, 1:]\n",
    "y = df.values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use a closure to store the related variables\n",
    "def create_plot_hierarchical(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    n_classes = len(np.unique(y))\n",
    "    def plot_hierarchical(threshold=1.0, method='single'):\n",
    "        expand = 1\n",
    "        linkage = hierarchy.linkage(X, method=method, metric='euclidean')\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "        \n",
    "        hierarchy.dendrogram(linkage,\n",
    "                   labels=y,\n",
    "                   leaf_rotation=0,\n",
    "                   leaf_font_size=7,\n",
    "                   color_threshold=threshold, \n",
    "                   ax=ax1)\n",
    "        \n",
    "        y_predicted = hierarchy.fcluster(linkage, t=threshold, criterion='distance')\n",
    "        \n",
    "        n_clusters = len(np.unique(y_predicted))\n",
    "        \n",
    "        matrix = np.zeros((n_clusters, n_classes))\n",
    "        for cluster in range(n_clusters):\n",
    "            for cl in range(n_classes):\n",
    "                matrix[cluster, cl] = np.sum(y[y_predicted == cluster+1]==cl)\n",
    "        sns.heatmap(matrix, annot=True, fmt='g', ax=ax2)\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Cluster')\n",
    "        print('Homogenity:', metrics.homogeneity_score(y, y_predicted))\n",
    "        print('Completeness:', metrics.completeness_score(y, y_predicted))\n",
    "        plt.show()\n",
    "    return plot_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_widget = widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=0.0,\n",
    "    max=10.0,\n",
    "    step=0.05,\n",
    "    continuous_update=False,\n",
    "    description='Threshold:')\n",
    "methods = ['single', 'complete', 'average', 'ward']\n",
    "interact(create_plot_hierarchical(X_scaled, y),\n",
    "         threshold=threshold_widget, method=methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
