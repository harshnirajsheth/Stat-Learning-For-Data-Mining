{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Python overview (8/27/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1. Artificial data</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>First, let's generate data with 2 classes: the first class is located around point (2,2). And the second one is around (-2, 0).</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# To maintain consistent results\n",
    "np.random.seed(520)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples in every class\n",
    "n = 10000\n",
    "# Generating the data\n",
    "X = np.random.normal(0, 1.0, (2*n, 2))\n",
    "# Shifting the data towards the expecting means\n",
    "X[0:n, :] += 2\n",
    "X[n:2*n, 0] -= 2\n",
    "# Just in case, to have data for each class separately\n",
    "X_0 = X[0:n, :]\n",
    "X_1 = X[n:2*n, :]\n",
    "# Generating the labels\n",
    "Y = np.zeros(2*n)\n",
    "Y[n:2*n] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Now, let's check the data: calculate some statistics and display it. Does it look correct?</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_0, axis=0))\n",
    "print(np.mean(X_1, axis=0))\n",
    "print(np.std(X_0, axis=0))\n",
    "print(np.std(X_1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the 2d data\n",
    "def plot(X, Y):\n",
    "    alpha=0.05\n",
    "    X_0 = X[Y==0, :]\n",
    "    X_1 = X[Y==1, :]\n",
    "    plt.plot(X_0[:, 0], X_0[:, 1], 'ro', alpha=alpha)\n",
    "    plt.plot(X_1[:, 0], X_1[:, 1], 'bo', alpha=alpha)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Simulated data')\n",
    "    plt.show()\n",
    "\n",
    "plot(X, Y)\n",
    "plt.hist(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Now, let's create a simple classifier for that data</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>First, let's divide the data into train and test</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=520, shuffle=True)\n",
    "\n",
    "plot(X_train, Y_train)\n",
    "plt.hist(Y_train)\n",
    "plt.show()\n",
    "plot(X_test, Y_test)\n",
    "plt.hist(Y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Second, create and fit a classifier. Here we will use a logistic regression</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=520, solver='liblinear')\n",
    "classifier.fit(X_train, Y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "predicted_proba = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test)\n",
    "print(predicted)\n",
    "print(predicted_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Third, we need to evaluate the model</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "cm = confusion_matrix(Y_test, predicted)\n",
    "print('Accuracy:', accuracy_score(Y_test, predicted)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "plt.figure()\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(Y_test, predicted_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve (area = %f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>2. Real data. Iris dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper **\"The use of multiple measurements in taxonomic problems\"** as an example of linear discriminant analysis.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (**Iris setosa**, **Iris virginica** and **Iris versicolor**). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>First, let's load the dataset</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Using pandas to write dataset to file and read it again</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                  columns=iris['feature_names'] + ['target'])\n",
    "df.style.hide_index()\n",
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to file\n",
    "df.to_csv('data_iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv('data_iris.csv', index_col=0)\n",
    "print(df_loaded[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Visualizing the data</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_loaded['target']\n",
    "X = df_loaded.values[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iris(X, Y):\n",
    "    alpha = 0.55\n",
    "    X_0 = X[Y==0, :]\n",
    "    X_1 = X[Y==1, :]\n",
    "    X_2 = X[Y==2, :]\n",
    "    plt.plot(X_0[:, 0], X_0[:, 1], 'ro', alpha=alpha)\n",
    "    plt.plot(X_1[:, 0], X_1[:, 1], 'bo', alpha=alpha)\n",
    "    plt.plot(X_2[:, 0], X_2[:, 1], 'go', alpha=alpha)\n",
    "    plt.xlabel(df.columns[0])\n",
    "    plt.ylabel(df.columns[1])\n",
    "    plt.title('IRIS dataset')\n",
    "    plt.show()\n",
    "    \n",
    "plot_iris(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_loaded['target']\n",
    "X = df_loaded.values[:, 2:4]\n",
    "\n",
    "def plot_iris(X, Y):\n",
    "    alpha = 0.55\n",
    "    X_0 = X[Y==0, :]\n",
    "    X_1 = X[Y==1, :]\n",
    "    X_2 = X[Y==2, :]\n",
    "    plt.plot(X_0[:, 0], X_0[:, 1], 'ro', alpha=alpha)\n",
    "    plt.plot(X_1[:, 0], X_1[:, 1], 'bo', alpha=alpha)\n",
    "    plt.plot(X_2[:, 0], X_2[:, 1], 'go', alpha=alpha)\n",
    "    plt.xlabel(df.columns[2])\n",
    "    plt.ylabel(df.columns[3])\n",
    "    plt.title('IRIS dataset')\n",
    "    plt.show()\n",
    "    \n",
    "plot_iris(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Splitting into train and test</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:, :-1]\n",
    "Y = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=520, shuffle=True)\n",
    "plt.hist(Y)\n",
    "plt.show()\n",
    "plt.hist(Y_train)\n",
    "plt.show()\n",
    "plt.hist(Y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Training the classifier</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "predicted_proba = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Evaluating the model</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, predicted)\n",
    "# To narmalize the confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)\n",
    "print('Accuracy:', accuracy_score(Y_test, predicted)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add confusion matrix visualization\n",
    "import seaborn as sn\n",
    "plt.figure()\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(X_train)\n",
    "predicted_proba = classifier.predict_proba(X_train)[:, 1]\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(Y_train, predicted)\n",
    "# To narmalize the confusion matrix\n",
    "cm = cm.astype('float') / cm.sum(axis=1)\n",
    "print('Accuracy:', accuracy_score(Y_train, predicted)*100)\n",
    "# TODO: Add confusion matrix visualization\n",
    "import seaborn as sn\n",
    "plt.figure()\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
