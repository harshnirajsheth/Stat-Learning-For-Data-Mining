{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Bayesian Network (11/07/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "# To load datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# To import the models (Decision Tree Classifier and Regressor)\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# To display a tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# To measure accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split, GridSearchCV\n",
    "\n",
    "# To support plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import math\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function to plot trees, taken from scikit-learn/sklearn/tree/export.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "class DummyScaler:\n",
    "    \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "def create_scaler_dummy():\n",
    "    return DummyScaler()\n",
    "    \n",
    "def create_scaler_standard():\n",
    "    return StandardScaler()\n",
    "\n",
    "def create_scaler_minmax():\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def crete_scaler_binarizer():\n",
    "    return Binarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Toy dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Prepare the dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\" as an example of linear discriminant analysis.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(True)\n",
    "\n",
    "def discretize_x(x, bins=2):\n",
    "    for i in range(x.shape[1]):  \n",
    "        x[:, i] = pd.qcut(x[:, i], bins, labels=False, duplicates='drop')\n",
    "    return x\n",
    "\n",
    "print(X.shape)\n",
    "X = discretize_x(X, 10)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=520)\n",
    "data_train = np.concatenate([X_train, y_train.reshape((y_train.shape[0], 1))], axis=1)\n",
    "data_test = np.concatenate([X_test, y_test.reshape((y_test.shape[0], 1))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trim the data to have just first 2 variables (length and width of the sepals).\n",
    "Also, let's remove repeating instances (just to make visualization more tractable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Bayesian Network</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should use that to install pomegranate\n",
    "# conda install pomegranate\n",
    "from pomegranate import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatch\n",
    "def plot_graph(structure, labels):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for label in labels:\n",
    "        G.add_node(label)\n",
    "    \n",
    "    edges = []\n",
    "    for t in range(len(structure)):\n",
    "        for f in structure[t]:\n",
    "            edges.append((labels[f], labels[t]))\n",
    "    \n",
    "    \n",
    "    G.add_edges_from(edges)\n",
    "    # Need to create a layout when doing\n",
    "    # separate calls to draw nodes and edges\n",
    "    pos = nx.shell_layout(G)\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='black', node_size=1000)# , cmap=plt.get_cmap('jet'))\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_color='w')\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='r', arrowstyle=mpatch.ArrowStyle.CurveB(head_length=3.0, head_width=0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'chow-liu', 'greedy', 'exact', 'exact-dp'\n",
    "model = BayesianNetwork.from_samples(data_train, max_parents=2, algorithm='exact-dp', reduce_dataset=True, n_jobs=-1)\n",
    "# print(model.structure)\n",
    "plot_graph(model.structure, ['X' + str(x) for x in range(X.shape[1])] + ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.states[0].distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = model.predict(np.concatenate([X_train, np.full((X_train.shape[0], 1), np.nan)], axis=1))\n",
    "y_test_hat = model.predict(np.concatenate([X_test, np.full((X_test.shape[0], 1), np.nan)], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = np.array([x[4] for x in y_train_hat])\n",
    "y_test_hat = np.array([x[4] for x in y_test_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (train):', metrics.accuracy_score(y_train, y_train_hat))\n",
    "cm = metrics.confusion_matrix(y_train, y_train_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (test):', metrics.accuracy_score(y_test, y_test_hat))\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Real-world dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Load the dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider that dataset:\n",
    "https://archive.ics.uci.edu/ml/datasets/mushroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the data set are:\n",
    "\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
    "4. bruises?: bruises=t,no=f\n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "7. gill-spacing: close=c,crowded=w,distant=d\n",
    "8. gill-size: broad=b,narrow=n\n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
    "10. stalk-shape: enlarging=e,tapering=t\n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "16. veil-type: partial=p,universal=u\n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "18. ring-number: none=n,one=o,two=t\n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
    "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'class',\n",
    "    'cap-shape',\n",
    "    'cap-surface',\n",
    "    'cap-color',\n",
    "    'bruises',\n",
    "    'odor',\n",
    "    'gill-attachment',\n",
    "    'gill-spacing',\n",
    "    'gill-size',\n",
    "    'gill-color',\n",
    "    'stalk-shape',\n",
    "    'stalk-root',\n",
    "    'stalk-surface-above-ring',\n",
    "    'stalk-surface-below-ring',\n",
    "    'stalk-color-above-ring',\n",
    "    'stalk-color-below-ring',\n",
    "    'veil-type',\n",
    "    'veil-color',\n",
    "    'ring-number',\n",
    "    'ring-type',\n",
    "    'spore-print-color',\n",
    "    'population',\n",
    "    'habitat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data', header=None, names=labels, na_values='?')\n",
    "#data = data.sample(frac=0.3, random_state=520)\n",
    "del data['stalk-root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_df(df):\n",
    "    df_num = df.copy()\n",
    "    for col in df.columns:\n",
    "        print(col)\n",
    "        print(df_num[col].astype('category').cat.categories)\n",
    "        df_num[col] = np.array(df_num[col].astype('category').cat.codes, dtype='float')\n",
    "    df_num[df_num == -1.0] = np.nan\n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = categorize_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data_num, test_size=0.2, random_state=520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.values[:, 1:]\n",
    "X_test = data_test.values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(data_train['class'])\n",
    "y_test = np.array(data_test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_predict = data_train.copy().values\n",
    "data_train_predict[:, 0] = np.nan\n",
    "data_test_predict = data_test.copy().values\n",
    "data_test_predict[:, 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNetwork.from_samples(data_train.to_numpy(), max_parents=2, algorithm='chow-liu', reduce_dataset=True, n_jobs=-1)\n",
    "plot_graph(model.structure, ['y'] + ['X' + str(x) for x in range(data_train.shape[1]-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = model.predict(data_train_predict, n_jobs=-1, check_input=False)\n",
    "y_test_hat = model.predict(data_test_predict, n_jobs=-1, check_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = np.array([x[0] for x in y_train_hat])\n",
    "y_test_hat = np.array([x[0] for x in y_test_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (train):', metrics.accuracy_score(y_train, y_train_hat))\n",
    "cm = metrics.confusion_matrix(y_train, y_train_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (BN, train)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (test):', metrics.accuracy_score(y_test, y_test_hat))\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (BN, test)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.delete(X_train, 10, axis=1)\n",
    "X_test2 = np.delete(X_test, 10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_tree = GridSearchCV(DecisionTreeClassifier(random_state=520),\n",
    "                          cv=5,\n",
    "                          param_grid={\n",
    "                              \"max_depth\": list(range(1, 40, 2)),\n",
    "                              \"min_samples_split\": list(range(2, 5, 2))\n",
    "                          })\n",
    "model_tree.fit(X_train2, y_train)\n",
    "print('The parameters found by CV search:')\n",
    "print(model_tree.best_params_)\n",
    "y_train_hat = model_tree.predict(X_train2)\n",
    "y_test_hat = model_tree.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (train):', metrics.accuracy_score(y_train, y_train_hat))\n",
    "cm = metrics.confusion_matrix(y_train, y_train_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (Tree, train)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (test):', metrics.accuracy_score(y_test, y_test_hat))\n",
    "cm = metrics.confusion_matrix(y_test, y_test_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (Tree, test)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_predict = data_test.copy().values\n",
    "data_test_y = data_test.values[:, 5]\n",
    "data_test_predict[:, 5] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_hat = model.predict(data_test_predict, n_jobs=-1, check_input=False)\n",
    "data_test_y_hat = np.array([x[5] for x in data_test_y_hat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_test_y_hat)\n",
    "print(data_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy (test):', metrics.accuracy_score(data_test_y, data_test_y_hat))\n",
    "cm = metrics.confusion_matrix(data_test_y, data_test_y_hat)\n",
    "ax = sn.heatmap(cm, annot=True, fmt='g', square=True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix (BN, different variable)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
