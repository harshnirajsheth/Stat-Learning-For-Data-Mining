{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Support Vector Machines (10/10/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: TO SUPPORT INTERACTIVE PLOTS IN JUPYTER LAB, RUN**\n",
    "\n",
    "conda install -c conda-forge nodejs\n",
    "\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "# To load datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# To import the classifier (SVM classifier)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# To measure accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "# To support plots\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "class DummyScaler:\n",
    "    \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "def create_scaler_dummy():\n",
    "    return DummyScaler()\n",
    "    \n",
    "def create_scaler_standard():\n",
    "    return StandardScaler()\n",
    "\n",
    "def create_scaler_minmax():\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def crete_scaler_binarizer():\n",
    "    return Binarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Toy dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Prepare the dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\" as an example of linear discriminant analysis.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trim the data to have just 2 variables and 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = X[:, 1:3]\n",
    "X_trimmed = X_trimmed[y != 0, :]\n",
    "y_trimmed = y[y != 0]\n",
    "\n",
    "create_scaler = create_scaler_minmax\n",
    "scaler = create_scaler()\n",
    "scaler.fit(X_trimmed)\n",
    "X_trimmed = scaler.transform(X_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_trimmed[:, 0], X_trimmed[:, 1], c=y_trimmed, s=30, cmap=plt.cm.bwr)\n",
    "plt.title('Visualization of reduced iris problem')\n",
    "plt.xlabel('Sepal width')\n",
    "plt.ylabel('Petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Support Vector Machines Classifier (choice of kernel)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a full list of parameters here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Here we use closure to store the related variables\n",
    "def create_plot_svm_classification_kernels(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    def plot_svc_kernel(C=1, kernel='linear'):\n",
    "        if kernel.startswith('poly'):\n",
    "            clf = SVC(kernel='poly', C=C, gamma='auto', degree=int(kernel[4:]))\n",
    "        else:\n",
    "            clf = SVC(kernel=kernel, C=C, gamma='auto')\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot((np.min(X[:, 0]), np.max(X[:, 0])), (np.min(X[:, 1]), np.max(X[:, 1])), alpha=0.0)\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "        v = max(np.max(Z), -np.min(Z))\n",
    "        cf = ax.contourf(XX, YY, Z, 100, cmap='coolwarm', norm = matplotlib.colors.Normalize(vmin=-v, vmax=v), alpha=0.1)\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.bwr)\n",
    "        ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "                   linestyles=['--', '-', '--'], linewidths=[2, 5, 2])\n",
    "\n",
    "        ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "                   linewidth=1, facecolors='none', edgecolors='k')\n",
    "        \n",
    "        plt.xlabel('Sepal width')\n",
    "        plt.ylabel('Petal length')\n",
    "        plt.title('Support Vector Machines Classifier: C=%s, %s kernel.' % (str(C), kernel))\n",
    "        plt.show()\n",
    "    return plot_svc_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear'] + ['poly'+str(x) for x in range(1, 9)] + ['rbf']\n",
    "ะก_widget = widgets.FloatLogSlider(\n",
    "    value=10,\n",
    "    base=10,\n",
    "    min=-4,\n",
    "    max=4,\n",
    "    step=0.5,\n",
    "    continuous_update=False,\n",
    "    description='C')\n",
    "interact(create_plot_svm_classification_kernels(X_trimmed, y_trimmed), C=ะก_widget, kernel=kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Support Vector Machines Classifier (RBF)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use closure to store the related variables\n",
    "def create_plot_svm_classification_rbf(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    def plot_svc_rbf(C=1, gamma=1):\n",
    "\n",
    "        clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.bwr)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "        Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "        v = max(np.max(Z), -np.min(Z))\n",
    "        cf = ax.contourf(XX, YY, Z, 100, cmap='coolwarm', norm = matplotlib.colors.Normalize(vmin=-v, vmax=v), alpha=0.1)\n",
    "        ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "                   linestyles=['--', '-', '--'], linewidths=[2, 5, 2])\n",
    "\n",
    "        ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "                   linewidth=1, facecolors='none', edgecolors='k')\n",
    "\n",
    "        plt.xlabel('Sepal width')\n",
    "        plt.ylabel('Petal length')\n",
    "        plt.title('Support Vector Machines Classifier: C=%s, Gamma=%s.' % (str(C), str(gamma)))\n",
    "        plt.show()\n",
    "    return plot_svc_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ะก_widget = widgets.FloatLogSlider(\n",
    "    value=1,\n",
    "    base=10,\n",
    "    min=-4,\n",
    "    max=3,\n",
    "    step=0.5,\n",
    "    continuous_update=False,\n",
    "    description='C:')\n",
    "gamma_widget = widgets.FloatLogSlider(\n",
    "    value=1,\n",
    "    base=10,\n",
    "    min=-4,\n",
    "    max=3,\n",
    "    step=0.5,\n",
    "    continuous_update=False,\n",
    "    description='gamma:')\n",
    "interact(create_plot_svm_classification_rbf(X_trimmed, y_trimmed), C=ะก_widget, gamma=gamma_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM accuracy on a grid of parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=520)\n",
    "\n",
    "create_scaler = create_scaler_minmax\n",
    "scaler = create_scaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def plot_param_search_rbf(X_train, y_train, X_test, y_test, Cs, gammas):\n",
    "    def compute_accuracy(C, gamma):\n",
    "        clf = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        clf.fit(X_train, y_train)\n",
    "        return clf.score(X_test, y_test)\n",
    "\n",
    "    Cs = np.power(10, np.linspace(-3, 4, num=20, endpoint=True))\n",
    "    gammas = np.power(10, np.linspace(-3, 4, num=20, endpoint=True))\n",
    "\n",
    "    C_mesh, gamma_mesh = np.meshgrid(Cs, gammas)\n",
    "    Z = np.zeros(C_mesh.shape)\n",
    "    for i in range(len(gammas)):\n",
    "        for j in range(len(Cs)):\n",
    "            Z[i, j] = compute_accuracy(C_mesh[i, j], gamma_mesh[i, j])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.contourf(gamma_mesh, C_mesh, Z, 50, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Gamma')\n",
    "    ax.set_ylabel('C')\n",
    "    plt.show()\n",
    "\n",
    "Cs = np.power(10, np.linspace(-3, 4, num=20, endpoint=True))\n",
    "gammas = np.power(10, np.linspace(-3, 4, num=20, endpoint=True))\n",
    "plot_param_search_rbf(X_train, y_train, X_test, y_test, Cs, gammas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Hyperparameter search</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Dataset</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "# The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, \n",
    "# based on certain diagnostic measurements included in the dataset. \n",
    "# Several constraints were placed on the selection of these instances from a larger database. \n",
    "# In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "# 1. Number of times pregnant\n",
    "# 2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "# 3. Diastolic blood pressure (mm Hg)\n",
    "# 4. Triceps skin fold thickness (mm)\n",
    "# 5. 2-Hour serum insulin (mu U/ml)\n",
    "# 6. Body mass index (weight in kg/(height in m)^2)\n",
    "# 7. Diabetes pedigree function\n",
    "# 8. Age (years)\n",
    "# 9. Class variable (0 or 1)\n",
    "\n",
    "names=['Pregnancies', 'Glucose', 'BloodPressure', \n",
    "       'SkinThickness', 'Insulin', 'BMI',\n",
    "       'DiabetesPedigreeFunction', 'Age', 'Class']\n",
    "data = pd.read_csv('https://gist.githubusercontent.com/ktisha/c21e73a1bd1700294ef790c56c8aec1f/raw/819b69b5736821ccee93d05b51de0510bea00294/pima-indians-diabetes.csv', skiprows=9, header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove all the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Glucose'] != 0]\n",
    "data = data[data['BloodPressure'] != 0]\n",
    "data = data[data['SkinThickness'] != 0]\n",
    "data = data[data['Insulin'] != 0]\n",
    "data = data[data['BMI'] != 0]\n",
    "data = data[data['Age'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "y = vals[:, -1]\n",
    "X = vals[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train and test. Also, we need to scale the data before using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=520)\n",
    "\n",
    "create_scaler = create_scaler_minmax\n",
    "scaler = create_scaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Hyperparameter search (rbf)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomizedSearchCV(SVC(kernel='rbf', random_state=520),\n",
    "                           cv=5,\n",
    "                           n_iter=40,\n",
    "                           n_jobs=-1,\n",
    "                           iid=True,\n",
    "                           param_distributions={\n",
    "                               'C': [10**x for x in range(-3, 4)], \n",
    "                               'gamma': [10**x for x in range(-3, 4)]\n",
    "                           })\n",
    "\n",
    "# model = GridSearchCV(SVC(kernel='rbf', random_state=520),\n",
    "#                          cv=5,\n",
    "#                          n_jobs=-1,\n",
    "#                          iid=True,\n",
    "#                          param_grid={\n",
    "#                              'C': [10**x for x in range(-3, 4)], \n",
    "#                              'gamma': [10**x for x in range(-3, 4)]\n",
    "#                          })\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print('Optimal parameters:', model.best_params_)\n",
    "\n",
    "y_test_hat = model.predict(X_test)\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_test_hat))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.power(10, np.linspace(-3, 4, num=40, endpoint=True))\n",
    "gammas = np.power(10, np.linspace(-3, 4, num=40, endpoint=True))\n",
    "plot_param_search_rbf(X_train, y_train, X_test, y_test, Cs, gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
