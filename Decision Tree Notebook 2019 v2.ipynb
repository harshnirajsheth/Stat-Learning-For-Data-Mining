{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>IEE 520: Fall 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Decision Tree (10/24/19)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Klim Drobnyh (klim.drobnyh@asu.edu)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: TO SUPPORT INTERACTIVE PLOTS IN JUPYTER LAB, RUN**\n",
    "\n",
    "conda install -c conda-forge nodejs\n",
    "\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility with Python 2\n",
    "from __future__ import print_function\n",
    "\n",
    "# To load datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "# To import the models (Decision Tree Classifier and Regressor)\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# To display a tree\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# To measure accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "# To support plots\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "# To display all the plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function to plot trees, taken from scikit-learn/sklearn/tree/export.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To increase quality of figures\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "class DummyScaler:\n",
    "    \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "def create_scaler_dummy():\n",
    "    return DummyScaler()\n",
    "    \n",
    "def create_scaler_standard():\n",
    "    return StandardScaler()\n",
    "\n",
    "def create_scaler_minmax():\n",
    "    return MinMaxScaler()\n",
    "\n",
    "def crete_scaler_binarizer():\n",
    "    return Binarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Toy dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Prepare the dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems\" as an example of linear discriminant analysis.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's trim the data to have just first 2 variables (length and width of the sepals).\n",
    "Also, let's remove repeating instances (just to make visualization more tractable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trimmed = X[:, :2]\n",
    "X_trimmed, indxs = np.unique(X_trimmed, return_index=True, axis=0)\n",
    "y_trimmed = y[indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iris(X, y):\n",
    "    alpha = 1.0\n",
    "    X_0 = X[y==0, :]\n",
    "    X_1 = X[y==1, :]\n",
    "    X_2 = X[y==2, :]\n",
    "    plt.plot(X_0[:, 0], X_0[:, 1], 'ro', alpha=alpha)\n",
    "    plt.plot(X_1[:, 0], X_1[:, 1], 'go', alpha=alpha)\n",
    "    plt.plot(X_2[:, 0], X_2[:, 1], 'bo', alpha=alpha)\n",
    "    plt.xlabel('Sepal length (cm)')\n",
    "    plt.ylabel('Sepal width (cm)')\n",
    "    plt.title('IRIS dataset')\n",
    "    plt.show()\n",
    "\n",
    "plot_iris(X_trimmed, y_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Decision Tree Classifier</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a full list of parameters here:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use closure to store the related variables\n",
    "def create_plot_dt_iris(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    X_0 = X[y==0, :]\n",
    "    X_1 = X[y==1, :]\n",
    "    X_2 = X[y==2, :]\n",
    "    def plot_dt_iris(max_depth=1, min_samples_split=2, expand=3.1):\n",
    "        alpha=0.8\n",
    "        model = DecisionTreeClassifier(max_depth=max_depth, \n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       random_state=520)\n",
    "                                       # class_weight='balanced')\n",
    "        model.fit(X, y)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        ax1.plot((np.min(X[:, 0])-expand, np.max(X[:, 0])+expand), \n",
    "                 (np.min(X[:, 1])-expand, np.max(X[:, 1])+expand), \n",
    "                 alpha=0.0)\n",
    "        xlim = ax1.get_xlim()\n",
    "        ylim = ax1.get_ylim()\n",
    "        xx = np.linspace(xlim[0], xlim[1], 100)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "        XX, YY = np.meshgrid(xx, yy)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = model.predict_proba(xy).reshape((XX.shape[0], XX.shape[1], -1))\n",
    "\n",
    "        ax1.imshow(Z, interpolation='bilinear',\n",
    "               origin='lower', extent=[xlim[0], xlim[1], ylim[0], ylim[1]])\n",
    "\n",
    "        ax1.scatter(X_0[:, 0], X_0[:, 1], s=80, linewidths=2, color='r', edgecolors='w')\n",
    "        ax1.scatter(X_1[:, 0], X_1[:, 1], s=80, linewidths=2, color='g', edgecolors='w')\n",
    "        ax1.scatter(X_2[:, 0], X_2[:, 1], s=80, linewidths=2, color='b', edgecolors='w')\n",
    "\n",
    "        ax1.set_xlabel('Sepal length (cm)')\n",
    "        ax1.set_ylabel('Sepal width (cm)')\n",
    "        ax1.set_title('Decision Tree Classifier: ' +\n",
    "                      'maximum depth:%s, minimal samples for split:%s' % \n",
    "                      (str(max_depth), str(min_samples_split)))\n",
    "        annotations = plot_tree(model, ax=ax2, feature_names=['x', 'y'], filled=True)\n",
    "        for annotation in annotations:\n",
    "            text = annotation.get_text()\n",
    "            vals = text[text.rfind('[') + 1:]\n",
    "            vals = vals[:vals.find(']')]\n",
    "            vals = [float(x) for x in vals.split(',')]\n",
    "            vals_sum = sum(vals)\n",
    "            vals = [x / vals_sum for x in vals]\n",
    "            annotation.set_color('w')\n",
    "            annotation.set_backgroundcolor(vals)\n",
    "        plt.show()\n",
    "    return plot_dt_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_widget = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    continuous_update=False,\n",
    "    description='Max depth:')\n",
    "min_samples_split_widget = widgets.IntSlider(\n",
    "    value=2,\n",
    "    min=2,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    continuous_update=False,\n",
    "    description='Min split:')\n",
    "expand_widget = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.1,\n",
    "    continuous_update=False,\n",
    "    description='Expand:')\n",
    "interact(create_plot_dt_iris(X_trimmed, y_trimmed), \n",
    "         max_depth=max_depth_widget, \n",
    "         min_samples_split=min_samples_split_widget,\n",
    "         expand=expand_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Real-world dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Load the dataset</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider that dataset:\n",
    "http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contain estimates of the percentage of body fat determined by underwater weighing and various body circumference measurements for 252 men.\n",
    "\n",
    "Accurate measurement of body fat is inconvenient/costly and it is desirable to have easy methods of estimating body fat that are not inconvenient/costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables in the data set are:\n",
    "\n",
    "* Density determined from underwater weighing\n",
    "* Percent body fat from Siri's (1956) equation\n",
    "* Age (years)\n",
    "* Weight (lbs)\n",
    "* Height (inches)\n",
    "* Neck circumference (cm)\n",
    "* Chest circumference (cm)\n",
    "* Abdomen 2 circumference (cm)\n",
    "* Hip circumference (cm)\n",
    "* Thigh circumference (cm)\n",
    "* Knee circumference (cm)\n",
    "* Ankle circumference (cm)\n",
    "* Biceps (extended) circumference (cm)\n",
    "* Forearm circumference (cm)\n",
    "* Wrist circumference (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://staff.pubhealth.ku.dk/~tag/Teaching/share/data/Bodyfat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Decision Tree Regressor</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider very simple model: the input is density, the ouput is bodyfat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "X_simple = vals[:, 0:1]\n",
    "y_simple = vals[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    return math.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Greater is better to make sure the signs are not flipped\n",
    "rmse_score = metrics.make_scorer(rmse_loss, greater_is_better=True)\n",
    "\n",
    "max_depths = list(range(1, 15))\n",
    "train_score = np.zeros(len(max_depths))\n",
    "test_score = np.zeros(len(max_depths))\n",
    "\n",
    "for i in range(len(max_depths)):\n",
    "    model = DecisionTreeRegressor(max_depth=max_depths[i],\n",
    "                                  random_state=520)\n",
    "    cv_results = cross_validate(model, X_simple, y_simple, \n",
    "                                cv=10, return_train_score=True, \n",
    "                                scoring=rmse_score)\n",
    "    train_score[i] = np.mean(cv_results['train_score'])\n",
    "    test_score[i] = np.mean(cv_results['test_score'])\n",
    "\n",
    "plt.plot(max_depths, train_score, 'b', label='Train score')\n",
    "plt.plot(max_depths, test_score, 'r', label='Test score')\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(ticks=range(min(max_depths), max(max_depths)+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use closure to store the related variables\n",
    "def create_plot_bodyfat_simple(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=520)\n",
    "    def plot_bodyfat_simple(max_depth=1):\n",
    "        y_hat = np.zeros(y.shape)\n",
    "        # Cross-validation\n",
    "        for train, test in kfold.split(X, y):\n",
    "            model = DecisionTreeRegressor(max_depth=max_depth,\n",
    "                                          random_state=520)\n",
    "            model.fit(X[train], y[train])\n",
    "            y_hat[test] = model.predict(X[test])\n",
    "        plt.title('Predicted vs actual, max depth: %s' % (str(max_depth)))\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.scatter(y, y_hat)\n",
    "        plt.show()\n",
    "    return plot_bodyfat_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_widget = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    continuous_update=False,\n",
    "    description='Max depth:')\n",
    "interact(create_plot_bodyfat_simple(X_simple, y_simple), \n",
    "         max_depth=max_depth_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, let's consider more realistic model: the input containts all the measurements, the ouput is bodyfat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data.values\n",
    "X_complex = vals[:, 2:]\n",
    "y_complex = vals[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = list(range(1, 15))\n",
    "train_score = np.zeros(len(max_depths))\n",
    "test_score = np.zeros(len(max_depths))\n",
    "\n",
    "for i in range(len(max_depths)):\n",
    "    model = DecisionTreeRegressor(max_depth=max_depths[i],\n",
    "                                  random_state=520)\n",
    "    cv_results = cross_validate(model, X_complex, y_complex, cv=10, \n",
    "                                return_train_score=True, scoring=rmse_score)\n",
    "    train_score[i] = np.mean(cv_results['train_score'])\n",
    "    test_score[i] = np.mean(cv_results['test_score'])\n",
    "\n",
    "plt.plot(max_depths, train_score, 'b', label='Train score')\n",
    "plt.plot(max_depths, test_score, 'r', label='Test score')\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(ticks=range(min(max_depths), max(max_depths)+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use closure to store the related variables\n",
    "def create_plot_bodyfat_complex(_X, _y):\n",
    "    X, y = _X, _y\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=520)\n",
    "    def plot_bodyfat_complex(max_depth=1):\n",
    "        y_hat = np.zeros(y.shape)\n",
    "        # Cross-validation\n",
    "        for train, test in kfold.split(X, y):\n",
    "            model = DecisionTreeRegressor(max_depth=max_depth,\n",
    "                                          random_state=520)\n",
    "            model.fit(X[train], y[train])\n",
    "            y_hat[test] = model.predict(X[test])\n",
    "        plt.title('Predicted vs actual, max depth: %s' % (str(max_depth)))\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.scatter(y, y_hat)\n",
    "        plt.show()\n",
    "    return plot_bodyfat_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_widget = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=15,\n",
    "    step=1,\n",
    "    continuous_update=False,\n",
    "    description='Max depth:')\n",
    "interact(create_plot_bodyfat_complex(X_complex, y_complex), \n",
    "         max_depth=max_depth_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
